# Transformers

## Description:

This repo is a collection of PyTorch implementations of Transformer architectures. The goal is learning and experimentation.


## Resources:

1. [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
2. [On Layer Normalization in the Transformer Architecture](https://arxiv.org/abs/2002.04745)
